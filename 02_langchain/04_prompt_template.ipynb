{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_template() ë©”ì†Œë“œ\n",
    "* ë³€ìˆ˜ë¥¼ ì¤‘ê´„í˜¸ë¡œ ë¬¶ì–´ì„œ í…œí”Œë¦¿ì— ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['name'] input_types={} partial_variables={} template='{name}ì˜ ì§ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template ì •ì˜, {}ì•ˆì˜ ë‚´ìš©ì€ ì´í›„ì˜ ê°’ì´ ë“¤ì–´ê°ˆ ìë¦¬\n",
    "template = \"{name}ì˜ ì§ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# from_template ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ PromptTemplate ê°ì²´ë¥¼ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bearì˜ ì§ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "# prompt ìƒì„±(ì™„ì„±) format() ë©”ì†Œë“œë¥¼ ì´ìš©í•´ ë³€ìˆ˜ì— ê°’ì„ ë„£ìŒ\n",
    "prompt = prompt.format(name=\"bear\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} template='{language}ëŠ” ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{language}ëŠ” ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?\" \n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonì€ ê·€ë„ ë°˜ ë¡œì¸(Guido van Rossum)ì— ì˜í•´ 1989ë…„ì— ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì´ ì–¸ì–´ë¥¼ ë§Œë“¤ ë•Œ ì½”ë“œì˜ ê°€ë…ì„±ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ì˜€ê³ , ê°„ê²°í•˜ê³  ëª…í™•í•œ ë¬¸ë²•ì„ ì§€í–¥í–ˆìŠµë‹ˆë‹¤. Pythonì€ 1991ë…„ì— ì²« ë²ˆì§¸ ë²„ì „ì´ ê³µê°œë˜ì—ˆìœ¼ë©°, ì´í›„ë¡œë„ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•´ì™”ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ í˜•íƒœë¡œ ë³€ìˆ˜ë¥¼ ì‘ì„±í•´ì•¼ í•˜ì§€ë§Œ\n",
    "# ë³€ìˆ˜ê°€ í•œê°œì¼ ë•ŒëŠ” ë³€ìˆ˜ë§Œìœ¼ë¡œ ì‘ì„±ì´ ê°€ëŠ¥\n",
    "\n",
    "# print(chain.invoke({\"language\" : \"Python\"}))\n",
    "print(chain.invoke(\"Python\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate ê°ì²´ ìƒì„±ê³¼ ë™ì‹œì— prompt ìƒì„±\n",
    "* input_variable ì¸ìë¥¼ ì‚¬ìš©í•´ ë³€ìˆ˜ë¥¼ ì§€ì •í•œë‹¤.\n",
    "* í…œí”Œë¦¿ì— ì‘ì„±í•œ ë³€ìˆ˜ê°€ input_variablesì— ì—†ìœ¼ë©´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œì¤€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} template='{language}ëŠ” ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PhythonëŠ” ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template ì •ì˜\n",
    "template = \"{language}ëŠ” ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"language\"],\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "prompt.format(language=\"Phython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partial_variables**\n",
    "* ì—°ì‚°ì¤‘ ë¯¸ë¦¬ ê³„ì‚°ëœ ë³€ìˆ˜ë¥¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§€ì •í•´ ë„£ì„ ìˆ˜ ìˆë‹¤.\n",
    "* í•­ìƒ ê³µí†µëœ ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê³  ì‹¶ì€ ë³€ìˆ˜ê°€ ìˆì„ ê²½ìš° ì‚¬ìš© <br>\n",
    "ex) ë‚ ì§œ, ì‹œê°„\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language1'] input_types={} partial_variables={'language2': 'Java'} template='{language1}ê³¼ {language2}ëŠ” ê°ê° ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'\n"
     ]
    }
   ],
   "source": [
    "# template ì •ì˜\n",
    "template = \"{language1}ê³¼ {language2}ëŠ” ê°ê° ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ ìƒì„±\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"language1\"],\n",
    "    partial_variables={\n",
    "        \"language2\" : \"Java\" # dictionary í˜•íƒœë¡œ partial_variable ì‘ì„±\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pythonê³¼ JavaëŠ” ê°ê° ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(language1=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partial()**\n",
    "* ì—°ì‚°ì¤‘ì— ë¯¸ë¦¬ ê³„ì‚°ëœ ë³€ìˆ˜ë¥¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§€ì •í•´ì„œ ë„£ì„ ìˆ˜ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language1'] input_types={} partial_variables={'language2': 'JavaSccript'} template='{language1}ê³¼ {language2}ëŠ” ê°ê° ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?'\n"
     ]
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(language2=\"JavaSccript\")\n",
    "\n",
    "print(prompt_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Pythonê³¼ JavaSccriptëŠ” ê°ê° ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜ìš”?')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.invoke(\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonì€ ê·€ë„ ë°˜ ë¡œì¸(Guido van Rossum)ì— ì˜í•´ 1991ë…„ì— ì²˜ìŒ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” Pythonì„ ë§Œë“¤ ë•Œ ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ì‚¬ìš©ì˜ ìš©ì´ì„±ì„ ì¤‘ì‹œí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "JavaScriptëŠ” ë¸Œë Œë˜ ì•„ì´í¬(Brendan Eich)ì— ì˜í•´ 1995ë…„ì— ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ë‹¹ì‹œ ë„·ìŠ¤ì¼€ì´í”„(Netscape)ì—ì„œ ì¼í•˜ê³  ìˆì—ˆìœ¼ë©°, ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë™ì ì¸ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ JavaScriptë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë‘ ì–¸ì–´ ëª¨ë‘ í˜„ì¬ ë§¤ìš° ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìœ¼ë©°, ê°ê°ì˜ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_partial | llm\n",
    "\n",
    "print (chain.invoke(\"Python\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒŒì¼ë¡œ ë¶€í„° template ì½ì–´ì˜¤ê¸°\n",
    "* prompt í¸í•˜ê²Œ ì‘ì„± ë° ìˆ˜ì •\n",
    "* ìƒí™©ì— ë§ê²Œ íŒŒì¼ì„ ì‘ì„±í•´ë‘ë©´ í•„ìš”í•  ë•Œ ë§ˆë‹¤ êº¼ë‚´ì„œ ì“¸ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} template='{language} ì–¸ì–´ì— ëŒ€í•´ 3ì¤„ë¡œ ì„¤ëª…í•´ì¤˜.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/language_simple.yaml\", encoding =\"UTF-8\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python ì–¸ì–´ì— ëŒ€í•´ 3ì¤„ë¡œ ì„¤ëª…í•´ì¤˜.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(language=\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ì–¸ì–´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "ì–¸ì–´ì˜ íŠ¹ì§•ì„ ë‹¤ìŒì˜ ì–‘ì‹ì— ë§ê²Œ ì •ë¦¬í•˜ì„¸ìš”.\n",
      "300ì  ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
      "í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
      "---\n",
      "#ì–‘ì‹\n",
      "1. íŠ¹ì§•\n",
      "2. ì œì‘ì\n",
      "3. ëŒ€í‘œì ì¸ í”„ë ˆì„ì›Œí¬\n",
      "4. ë§ì´ ì‚¬ìš©ë˜ëŠ” ë¶„ì•¼\n",
      "\n",
      "input_variables: [\"language\"]\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"prompts/language.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "print(prompt2.format(language=\"Python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. íŠ¹ì§•: ìë°”ëŠ” ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, í”Œë«í¼ ë…ë¦½ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. \"Write Once, Run Anywhere\"ë¼ëŠ” ìŠ¬ë¡œê±´ ì•„ë˜, JVM(Java Virtual Machine)ì„ í†µí•´ ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê°•ë ¥í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ ì˜ˆì™¸ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ APIë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. ì œì‘ì: ìë°”ëŠ” 1995ë…„ ì¬ ë§ˆì´í¬ë¡œì‹œìŠ¤í…œì¦ˆ(Sun Microsystems)ì—ì„œ ì œì„ìŠ¤ ê³ ìŠ¬ë§(James Gosling)ì— ì˜í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ëŒ€í‘œì ì¸ í”„ë ˆì„ì›Œí¬: ìŠ¤í”„ë§(Spring), í•˜ì´ë²„ë„¤ì´íŠ¸(Hibernate), ìë°” ì„œë²„ í˜ì´ì¦ˆ(JavaServer Faces, JSF) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. ë§ì´ ì‚¬ìš©ë˜ëŠ” ë¶„ì•¼: ìë°”ëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜, ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜(ì•ˆë“œë¡œì´ë“œ), ê¸°ì—…ìš© ì†Œí”„íŠ¸ì›¨ì–´, ë¹…ë°ì´í„° ì²˜ë¦¬ ë° í´ë¼ìš°ë“œ ì»´í“¨íŒ… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt2 | ChatOpenAI(model_name = \"gpt-4o-mini\", temperature = 0.0) | StrOutputParser()\n",
    "\n",
    "answer = chain.invoke(\"Java\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate \n",
    "* ëŒ€í™” ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì£¼ì…í•˜ê³ ì í•  ë•Œ ì‚¬ìš© í•  ìˆ˜ ìˆë‹¤.\n",
    "* ë©”ì‹œì§€ëŠ” íŠœí”Œí˜•íƒœë¡œ ì „ë‹¬\n",
    "    * (\"role\",\"message\") êµ¬ì„±ë˜ê³ , ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ìƒì„± ê°€ëŠ¥\n",
    "\n",
    "**role**\n",
    "* system : ì‹œìŠ¤í…œ ì„¤ì •ë©”ì‹œì§€ë¡œ ì£¼ë¡œ ì „ì—­ ì„¤ì •ì„ í•  ë–„ ì‚¬ìš©\n",
    "* human : ì‚¬ìš©ìì˜ ì…ë ¥ ë©”ì‹œì§€ \n",
    "* ai : AIì˜ ë‹µë³€ ë©”ì‹œì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='{language}ì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{language}ì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\")\n",
    "\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Pyhtonì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(language=\"Pyhton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤íŠ¸ ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ êµ¬ì°Œ ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë°˜ê°€ì›Œìš”!', additional_kwargs={}, response_metadata={}), AIMessage(content='ì•ˆë…€í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        #role, message\n",
    "        (\"system\",\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤íŠ¸ ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ {name} ì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\",\"ë°˜ê°€ì›Œìš”!\"),\n",
    "        (\"ai\", \"ì•ˆë…€í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    name = \"êµ¬ì°Œ\", user_input = \"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\"\n",
    ")\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œ ì´ë¦„ì€ êµ¬ì°Œì…ë‹ˆë‹¤! ë‹¹ì‹ ê³¼ ëŒ€í™”í•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤. ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagePlaceHolder\n",
    "* ì•„ì§ í™•ì •ëœ ë©”ì‹œì§€ê°€ ì•„ë‹ˆì§€ë§Œ, ë‚˜ì¤‘ì— ì±„ì›Œì§ˆ ë©”ì‹œì§€ ìœ„ì¹˜ë¥¼ ì¡ì•„ë‘ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.\n",
    "* ë³´í†µ ëŒ€í™” ê¸°ë¡ì„ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['conversation', 'word_count'] input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022511BCC4A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì…ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count} ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì…ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\",\"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count} ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì…ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\n",
      "AI: ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\n",
      "Human: set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\n",
      "AI: ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\n",
      "Human: ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ 5 ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation =[\n",
    "        (\"human\", \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\"),\n",
    "        (\"ai\", \"ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\"),\n",
    "        (\"ai\", \"ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'íŒŒì´ì¬, ë¦¬ìŠ¤íŠ¸, ì¤‘ë³µ ì œê±°, set.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\n",
    "    \"word_count\":5,\n",
    "    \"conversation\" :[\n",
    "        (\"human\", \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\"),\n",
    "        (\"ai\", \"ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\"),\n",
    "        (\"ai\", \"ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (0.3.13)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.16.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\20107\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 33.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ” ì•½ 24ì‹œê°„ì…ë‹ˆë‹¤. ì´ë¥¼ \"í•˜ë£¨\"ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\\n\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama \n",
    "# model\n",
    "llm = Ollama(model=\"gemma2:9b\")\n",
    "\n",
    "response = llm.invoke(\"ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ”?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'íŒŒì´ì¬, ì¤‘ë³µ ì œê±°, set ì‚¬ìš©, ê°„ë‹¨ í•´ê²°.  \\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
